# AINLP-Archive

[AINLP公众号](http://www.52nlp.cn/%E6%AC%A2%E8%BF%8E%E5%85%B3%E6%B3%A8ainlp-%E4%B8%80%E4%B8%AA%E6%9C%89%E8%B6%A3%E6%9C%89ai%E7%9A%84nlp%E5%85%AC%E4%BC%97%E5%8F%B7) 公众号文章分类存档。欢迎关注AINLP公众号：

<p align=center><img src="./images/ainlp.jpg" width="300" height="300"></p>

[AINLP公众号](http://www.52nlp.cn/%E6%AC%A2%E8%BF%8E%E5%85%B3%E6%B3%A8ainlp-%E4%B8%80%E4%B8%AA%E6%9C%89%E8%B6%A3%E6%9C%89ai%E7%9A%84nlp%E5%85%AC%E4%BC%97%E5%8F%B7) 公众号文章分类存档, 每天更新。

<p><strong>如何学习NLP和NLP相关资源</strong><br>

<a href="https://mp.weixin.qq.com/s/tV26DJeFWfEe0DL3B7Z-cQ" target="_blank" rel="noopener">如何学习自然语言处理：一本书和一门课</a><br>

<a href="https://mp.weixin.qq.com/s/tyLRR2xKbFYEQ9WYM5ZKcg" target="_blank" rel="noopener">如何学习自然语言处理：NLP领域经典《自然语言处理综论》英文版第三版更新</a><br>

<a href="https://mp.weixin.qq.com/s/AdjO7ylfc28Qu_gCfOTFKA" rel="noopener" target="_blank">这门斯坦福大学自然语言处理经典入门课，我放到B站了</a><br>

<a href="https://mp.weixin.qq.com/s/hzv62vVx9jcYv94xZPmHPw" rel="noopener" target="_blank">数学之美中盛赞的 Michael Collins 教授，他的NLP课程要不要收藏？</a><br>

<a href="https://mp.weixin.qq.com/s/IXiAhufR9j5PR_YlRWlhCw" rel="noopener" target="_blank">学自然语言处理，其实更应该学好英语</a><br>

<a href="https://mp.weixin.qq.com/s/qnsvDQvPZSJG6rDtbFGggA" target="_blank" rel="noopener">李纪为博士：初入NLP领域的一些小建议</a><br>

<a href="https://mp.weixin.qq.com/s/E8vvzAP-4Mqd64kh4mL1iw" target="_blank" rel="noopener">老宋同学的学习建议和论文：听说你急缺论文大礼包？</a><br>

<a href="https://mp.weixin.qq.com/s/_0M4WzoAzcd3sNAi4T-Ilg" rel="noopener" target="_blank">从老宋的角度看，自然语言处理领域如何学习？</a><br>

<a href="https://mp.weixin.qq.com/s/N-6CjOLvL3p11v9dU85Gow" target="_blank" rel="noopener">刘知远老师NLP研究入门之道：NLP推荐书目</a><br>

<a href="https://mp.weixin.qq.com/s/wirkEdzEoTmwQn9JR0Np6A" target="_blank" rel="noopener">NLP研究入门之道：自然语言处理简介</a><br>

<a href="https://mp.weixin.qq.com/s/MlIEgLcjxq1-ujl-9Z_j6w" target="_blank" rel="noopener">NLP研究入门之道：走近NLP学术界</a><br>

<a href="https://mp.weixin.qq.com/s/43mjDdSzTv2CLSBjPivLlw" target="_blank" rel="noopener">NLP研究入门之道：如何通过文献掌握学术动态</a><br>

<a href="https://mp.weixin.qq.com/s/W4sOeJi11xxPw0b75Mrwaw" target="_blank" rel="noopener">NLP研究入门之道：如何写一篇合格的学术论文</a><br>

<a href="https://mp.weixin.qq.com/s/sEnmC1rSrZ6U4Iqtiey8eQ" target="_blank" rel="noopener">NLP研究入门之道：本科生如何开始科研训练</a><br>

<a href="https://mp.weixin.qq.com/s/pYSOysXipADV74YmkO9lEA" rel="noopener" target="_blank">自然语言理解难在哪儿？</a><br>

<a href="https://mp.weixin.qq.com/s/88mrVSz1JA0FB2-5toWCSg" rel="noopener" target="_blank">好的研究想法从哪里来</a><br>

<a href="https://mp.weixin.qq.com/s/iqAbAHr3fvyFcm3K1LR3kw" target="_blank" rel="noopener">你是如何了解或者进入NLP这个领域的？</a><br>

<a href="https://mp.weixin.qq.com/s/lfXOu32_0IbNz0lzx3eIog" target="_blank" rel="noopener">NLP is hard! 自然语言处理太难了系列</a></p>

<p><strong>NLP相关工具及在线测试（公众号对话测试）</strong><br>

<a href="https://mp.weixin.qq.com/s/Sy2hukGVk-7QQY_YNQ10kw" target="_blank" rel="noopener">五款中文分词工具在线PK: Jieba, SnowNLP, PkuSeg, THULAC, HanLP</a><br>

<a href="https://mp.weixin.qq.com/s/YvpVumIdBDA9vBjGeLoPZA" target="_blank" rel="noopener">中文分词工具在线PK新增：FoolNLTK、LTP、StanfordCoreNLP</a><br>

<a href="https://mp.weixin.qq.com/s/rFCBnExyZVHI-SwrSj7pmA" target="_blank" rel="noopener">Python中文分词工具大合集：安装、使用和测试</a><br>

<a href="https://mp.weixin.qq.com/s/LwtQVg9p_VBzwA_2uvX8GA" target="_blank" rel="noopener">八款中文词性标注工具使用及在线测试</a><br>

<a href="https://mp.weixin.qq.com/s/pOGdatZK5Z7uxmveHAX4_Q" target="_blank" rel="noopener">百度深度学习中文词法分析工具LAC试用之旅</a><br>

<a href="https://mp.weixin.qq.com/s/Vj0IKHWD_aXto8NE8alz8g" target="_blank" rel="noopener">来，试试百度的深度学习情感分析工具</a><br>

<a href="https://mp.weixin.qq.com/s/2y-TshJqNHW5ixzjbtdekg" target="_blank" rel="noopener">AINLP公众号新增SnowNLP情感分析模块</a><br>

<a href="https://mp.weixin.qq.com/s/pd_BcCG2DjtlgFsym8PwXw" rel="noopener" target="_blank">斯坦福大学NLP组Python深度学习自然语言处理工具Stanza试用</a><br>

<a href="https://mp.weixin.qq.com/s/gU9BkXzV35_2walQ5ndB_w" rel="noopener" target="_blank">中文命名实体识别工具（NER）哪家强？</a></p>

<p><strong>腾讯词向量和相似词、相似度、词语游戏系列</strong><br>

<a href="https://mp.weixin.qq.com/s/UwPwW8JzWVQrVwbPy9321g" target="_blank" rel="noopener">相似词查询：玩转腾讯 AI Lab 中文词向量</a><br>

<a href="https://mp.weixin.qq.com/s/Q533WJ7Kwtehwm8aLuKbDA" target="_blank" rel="noopener">玩转腾讯词向量：词语相似度计算和在线查询</a><br>

<a href="https://mp.weixin.qq.com/s/oboRxo9k4am4AUGmR5YG9Q" target="_blank" rel="noopener">腾讯词向量实战：通过Annoy进行索引和快速查询</a><br>

<a href="https://mp.weixin.qq.com/s/cMMVCFcBoDfcTZXhRty63w" target="_blank" rel="noopener">玩转腾讯词向量：Game of Words（词语的加减游戏）</a><br>

<a href="https://mp.weixin.qq.com/s/8BVerIljzZHX3KFnYedDgg" target="_blank" rel="noopener">词向量游戏：梅西-阿根廷+葡萄牙=?</a><br>

<a href="https://mp.weixin.qq.com/s/JB3Tg8s8YHfLL0kLtR92kw" rel="noopener" target="_blank">腾讯 800 万中文词向量 API Demo 搭建</a><br>

<a href="https://mp.weixin.qq.com/s/DNkZbxJclzWXPYarN14bPg" rel="noopener" target="_blank">相似词检索，近义词查询，同义词大全，这里不仅仅限于中文</a></p>

<p><strong>自动对联及作诗机</strong><br>

<a href="https://mp.weixin.qq.com/s/A6FMzXS0W7jyTMuyCgzJhw" target="_blank" rel="noopener">风云三尺剑，花鸟一床书---对联数据集和自动对联机器人</a><br>

<a href="https://mp.weixin.qq.com/s/VSPPEVcihLUcJMmh7h3hgA" target="_blank" rel="noopener">自动对联活动获奖结果以及机器对联赏析</a><br>

<a href="https://mp.weixin.qq.com/s/w8e0TixjbqvKXnZksL32tQ" target="_blank" rel="noopener">"自动作诗机"上线，代码和数据都是公开的</a><br>

<a href="https://mp.weixin.qq.com/s/Za1_atH01eUIQHHdo4M-Cg" rel="noopener" target="_blank">鼠年春节，用 GPT-2 自动写对联和对对联</a><br>

<a href="https://mp.weixin.qq.com/s/8nOhe0RDkgEgxWdjAsjpvw" rel="noopener" target="_blank">用 GPT-2 自动写诗，从五言绝句开始</a><br>

<a href="https://mp.weixin.qq.com/s/fdeyf2uwaHNac1_guj5L6Q" rel="noopener" target="_blank">自动作诗机&amp;藏头诗生成器：五言、七言、绝句、律诗全了</a><br>

<a href="https://mp.weixin.qq.com/s/OgWlf7GqidIX2ffVBUo_tQ" rel="noopener" target="_blank">仅供娱乐，藏尾诗生成器来了</a></p>

<p><strong>夸夸聊天机器人及其他技能</strong><br>

<a href="https://mp.weixin.qq.com/s/B0ilgxGnLPMYDny1FYmWHw" target="_blank" rel="noopener">一行Python代码实现夸夸聊天机器人</a><br>

<a href="https://mp.weixin.qq.com/s/pUhugd5WTru32M1l6Qrxzg" target="_blank" rel="noopener">为了夸夸聊天机器人，爬了一份夸夸语料库</a><br>

<a href="https://mp.weixin.qq.com/s/NO2M8_VD29uCaUuTrkzfyA" target="_blank" rel="noopener">夸夸聊天机器人升级：从随机到准个性化</a><br>

<a href="https://mp.weixin.qq.com/s/fSzWY835t1bgZsv901S_FA" target="_blank" rel="noopener">来，试试语音（识别）聊天（机器人）</a><br>

<a href="https://mp.weixin.qq.com/s/Fe1WJUaaXpe4gERZFmhUIw">来，试试成语接龙</a><br>

<a href="https://mp.weixin.qq.com/s/c5AXq0iNLC65Nwae-vnjXQ" rel="noopener" target="_blank">推荐一份中文数据，来试试汉字、词语、成语、歇后语在线检索</a><br>

<a href="https://mp.weixin.qq.com/s/Qnt-R_IY7N3eVhAvwNQ1ig" rel="noopener" target="_blank">AINLP公众号新增"狗屁不通文章生成器"接口</a><br>

<a href="https://mp.weixin.qq.com/s/lofYSXsgsFNSEqFyKaWhJA" rel="noopener" target="_blank">来，试试彩虹屁生成器</a></p>

<p><strong>深度学习基础</strong></p>

[四万字全面详解 | 深度学习中的注意力机制（完结篇）](https://mp.weixin.qq.com/s/rWju_3bTAcTdWcP83AGtyA)

[RealFormer：Real 简单，Real 有效](https://mp.weixin.qq.com/s/1CQgLlINHXR_yQxwjFQQ-A)

[Transformer哪家强？Google爸爸辨优良！](https://mp.weixin.qq.com/s/Agrt4Ic9wA59gZW4F5ZFcA)

[从零开始实现卷积神经网络CNN](https://mp.weixin.qq.com/s/Td5cK5gKzlx6N8mAtnTa8Q)

<p><strong>BERT及预训练模型</strong></p>

<a href="https://mp.weixin.qq.com/s/T3XjEir63GlasbXDPK2YUQ" rel="noopener" target="_blank">放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较</a><br>

<a href="https://mp.weixin.qq.com/s/LGJvvhotSg7XMn8mg3TZUw" target="_blank" rel="noopener">预训练在自然语言处理的发展: 从Word Embedding到BERT模型</a><br>

<a href="https://mp.weixin.qq.com/s/p16IEzlaDGRNt8h6WkP-dQ" target="_blank" rel="noopener">从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史</a><br>

<a href="https://mp.weixin.qq.com/s/WPkOMeXK5rE-KpBFeI-KAg" rel="noopener" target="_blank">Bert时代的创新（应用篇）：Bert在NLP各领域的应用进展</a><br>

<a href="https://mp.weixin.qq.com/s/0pYFb2POAcV1AKTLJ7t1DA" rel="noopener" target="_blank">效果惊人的GPT 2.0模型：它告诉了我们什么</a><br>

<a href="https://mp.weixin.qq.com/s/2nWZkWDWbtHEkWyTCKKuHw" rel="noopener" target="_blank">XLNet:运行机制及和Bert的异同比较</a></p>

<a href="https://mp.weixin.qq.com/s/9b3sqng5GfFFYuIr-qlvdw" rel="noopener" target="_blank">BERT源码分析PART I</a><br>

<a href="https://mp.weixin.qq.com/s/whZlOBhMpvUsWjCkKjRnAw" rel="noopener" target="_blank">BERT源码分析PART II</a><br>

<a href="https://mp.weixin.qq.com/s/lbL1a1vyU6p_hJ5EEahi5g" rel="noopener" target="_blank">BERT源码分析PART III</a><br>

<a href="https://mp.weixin.qq.com/s/b-HYzrSa4MF2zHYdxbtKcg" rel="noopener" target="_blank">站在BERT肩膀上的NLP新秀们（PART I）</a><br>

<a href="https://mp.weixin.qq.com/s/RIm0S6Psm5cDA4yqDjP49A" rel="noopener" target="_blank">站在BERT肩膀上的NLP新秀们（PART II）</a><br>

<a href="https://mp.weixin.qq.com/s/yXcpgr6oxowOYdQr9UhW0A" rel="noopener" target="_blank">站在BERT肩膀上的NLP新秀们（PART III）</a><br>

<a href="https://mp.weixin.qq.com/s/H-t2t2ccOW_el62ppt8CGg" rel="noopener" target="_blank">Nvidia League Player：来呀比到天荒地老</a><br>

<a href="https://mp.weixin.qq.com/s/K07zCIibmhC03L-JOHoaKg" rel="noopener" target="_blank">Dive into BERT：语言模型与知识</a><br>

<a href="https://mp.weixin.qq.com/s/_-GN-OI9DMYMyKBRKObvKA" rel="noopener" target="_blank">当BERT遇上知识图谱</a><br>

<a href="https://mp.weixin.qq.com/s/hGT8sKmjmeiD1pdrAepJqA" rel="noopener" target="_blank">中文预训练模型ERNIE超详细使用指南</a></p>

<a href="https://mp.weixin.qq.com/s/SNAPHnUpW6KPyN-dwj5LNw" rel="noopener" target="_blank">听说你还没读过 Bert 源码？</a><br>

<a href="https://mp.weixin.qq.com/s/aEk90uEVIuqqq9639CAQpA" rel="noopener" target="_blank">Bert 之后：预训练语言模型与自然语言生成</a><br>

<a href="https://mp.weixin.qq.com/s/aPkPlEPMFS0NrmD5r7Kfkg" rel="noopener" target="_blank">就最近看的paper谈谈预训练语言模型发展</a><br>

<a href="https://mp.weixin.qq.com/s/3b_2VbehBOYsnKCBSEio4w" rel="noopener" target="_blank">Bert 改进： 如何融入知识</a><br>

<a href="https://mp.weixin.qq.com/s/lYNKXHorx886F2lHPAJHvg" rel="noopener" target="_blank">ALBERT 告诉了我们什么？</a></p>

<a href="https://mp.weixin.qq.com/s/oqCRswaOhAEJ9GYZwKaKYA" rel="noopener" target="_blank">BERT论文笔记</a><br>

<a href="https://mp.weixin.qq.com/s/NBJZo8ztIsaaYe4ZvdwrVw" rel="noopener" target="_blank">XLNet 论文笔记</a><br>

<a href="https://mp.weixin.qq.com/s/gPKj5x0pSh50fP2fjqjrYA" rel="noopener" target="_blank">ERNIE Tutorial（论文笔记 + 实践指南）</a><br>

<a href="https://mp.weixin.qq.com/s/HXynRtAAprARWWxEeICG8g" rel="noopener" target="_blank">DistilBERT Understanding</a></p>

<a href="https://mp.weixin.qq.com/s/K1R_thLJqegm6QDj2GA5ww" rel="noopener" target="_blank">模型压缩实践系列之——layer dropout</a><br>

<a href="https://mp.weixin.qq.com/s/mkaQb-aauxED1mH1fdYTMA" rel="noopener" target="_blank">模型压缩实践系列之——bert-of-theseus，一个非常亲民的bert压缩方法</a><br>

<a href="https://mp.weixin.qq.com/s/PR_YrbbT8gnAx6A36D3_KQ" rel="noopener" target="_blank">模型压缩实践收尾篇——模型蒸馏以及其他一些技巧实践小结</a></p>

<a href="https://mp.weixin.qq.com/s/H4at_BDLwZWqlBHLjMZWRQ" rel="noopener" target="_blank">一步步理解BERT</a><br>

<a href="https://mp.weixin.qq.com/s/xvsc5RJ3CpiehoGsA-ml1g" rel="noopener" target="_blank">最新语言表示方法XLNet</a><br>

<a href="https://mp.weixin.qq.com/s/z4jihwif7Jx7OQ76p7JgxQ" rel="noopener" target="_blank">深度剖析知识增强语义表示模型——ERNIE</a></p>

<a href="https://mp.weixin.qq.com/s/t_VQ8-vNrgOoYz_cyVwhmQ" rel="noopener" target="_blank">NLP - 基于 BERT 的中文命名实体识别（NER)</a><br>

<a href="https://mp.weixin.qq.com/s/imPro1LZvGJ44ezoDOL5Dw" rel="noopener" target="_blank">NLP - BERT/ERNIE 文本分类和部署</a></p>

<a href="https://mp.weixin.qq.com/s/C5B4QO0fxWtBwA5iv3XzcA" rel="noopener" target="_blank">详解BERT阅读理解</a><br>

<a href="https://mp.weixin.qq.com/s/zOcbvoq26hmlniU_k26hrQ" rel="noopener" target="_blank">简单高效的Bert中文文本分类模型开发和部署</a></p>

<a href="https://mp.weixin.qq.com/s/q5OyrIycfN4fjQ33uSRmEA" target="_blank" rel="noopener">BERT相关论文、文章和代码资源汇总</a><br>

<a href="https://mp.weixin.qq.com/s/IndeECchmX_GC8MzuWSVfg" rel="noopener" target="_blank">12个NLP预训练模型的学习笔记</a><br>

<a href="https://mp.weixin.qq.com/s/VBX-EezsgK4QkQqaOKqObQ" rel="noopener" target="_blank">transformer-XL与XLNet笔记</a><br>

<a href="https://mp.weixin.qq.com/s/38Y3xf1F-lXxvi_RYTW76A" rel="noopener" target="_blank">Reformer: The Efficient Transformer</a><br>

<a href="https://mp.weixin.qq.com/s/yWl7EL33vWt64Mo7d9kyIw" rel="noopener" target="_blank">逆向而行，中文轻量级预训练模型的探索之路</a><br>

<a href="https://mp.weixin.qq.com/s/_sTGvbCb7BlKDYQhPYX7eg" rel="noopener" target="_blank">【NLP】ALBERT粗读（李如同学）</a><br>

<a href="https://mp.weixin.qq.com/s/u4k-A3dSb2-6PDodWPePhA" rel="noopener" target="_blank">BERT 的演进和应用</a><br>

<a href="https://mp.weixin.qq.com/s/U_pYc5roODcs_VENDoTbiQ" rel="noopener" target="_blank">吴金龙博士的解读：BERT时代与后时代的NLP</a><br>

<a href="https://mp.weixin.qq.com/s/V_-AHhUk5KLKm4LUfhf8vA" target="_blank" rel="noopener">谷歌BERT模型深度解析</a><br>

<a href="https://mp.weixin.qq.com/s/HhW7PcFhrVWjWt1qNx-anQ" rel="noopener" target="_blank">BERT_Paper_Chinese_Translation: BERT论文中文翻译版</a><br>

<a href="https://mp.weixin.qq.com/s/48y3gpPLs583Vv-QXpcnlQ" rel="noopener" target="_blank">【Github】BERT-train2deploy：BERT模型从训练到部署</a><br>

<a href="https://mp.weixin.qq.com/s/j0sHyTTfgdtMX3eAen0umw" rel="noopener" target="_blank">BERT/注意力机制/Transformer/迁移学习NLP资源大列表：awesome-bert-nlp</a><br>

<a href="https://mp.weixin.qq.com/s/DvbvYppeuMaPn84SRAINcQ" rel="noopener" target="_blank">NLP中的词向量对比：word2vec/glove/fastText/elmo/GPT/bert</a><br>

<a href="https://mp.weixin.qq.com/s/aXudh37BWRRz75BzqSTJ0w" rel="noopener" target="_blank">中文预训练ALBERT模型来了：小模型登顶GLUE，Base版模型小10倍速度快1倍</a><br>

<a href="https://mp.weixin.qq.com/s/pXtPJiY5yYsaRVb2Jn-qZA" rel="noopener" target="_blank">超小型bert横空出世：训练和预测提速10倍</a><br>

<a href="https://mp.weixin.qq.com/s/q3v1nwNrH8VTZIQ9lIxmcA" rel="noopener" target="_blank">RoBERTa for Chinese：大规模中文预训练RoBERTa模型</a><br>

<a href="https://mp.weixin.qq.com/s/8D9kYpoZy6GKN7zudKxNww" rel="noopener" target="_blank">中文语言理解基准测评(chineseGLUE)来了，公开征集数据集进行中</a><br>

<a href="https://mp.weixin.qq.com/s/Lzsuo6fIBPkiOJ6BLCsRPA" rel="noopener" target="_blank">CLUECorpus2020：可能是史上最大的开源中文语料库以及高质量中文预训练模型集合</a><br>

<a href="https://mp.weixin.qq.com/s/0rIXEX2NSmjNNA0PVRtmgQ" rel="noopener" target="_blank">最简单的BERT模型调用方法</a><br>

<a href="https://mp.weixin.qq.com/s/1rj8zGCp_SpyBCD-3PXjBw" rel="noopener" target="_blank">【Github】BERT-NER-Pytorch：三种不同模式的BERT中文NER实验</a></p>

[语言模型发展思路](https://mp.weixin.qq.com/s/v7YZ_Y2a_u2HfJx0sGqFOw)

[GPT-3的最强落地方式？陈丹琦提出小样本微调方法，比普通微调提升11%](https://mp.weixin.qq.com/s/nFuN2kwf-1JbgZflVrkf6w)

<p><strong>命名实体识别</strong></p>

[Transformer为啥在NER上表现不好](https://mp.weixin.qq.com/s/FVPR_PkMcgygTr8LbyRPIw)

<p><strong>文本生成</strong></p>

[如何让BERT具有文本生成能力](https://mp.weixin.qq.com/s/iNY_pk9sby4bC-wLFzrh0g)

<p><strong>对话系统</strong></p>

[CRSLab：可能是最适合你的对话推荐系统开源库](https://mp.weixin.qq.com/s/n9xP9R7gY7n3d890W0TXvw)

[达摩院基于元学习的对话系统](https://mp.weixin.qq.com/s/NCum-Qi8j6nTcPU-fm-uvA)

<p><strong>推荐算法/推荐系统</strong></p>

[推荐精排模型之经典排序模型](https://mp.weixin.qq.com/s/qPKBjON786i_x2N0OqS1Nw)

[推荐模型之DeepMCP模型](https://mp.weixin.qq.com/s/q2gEnuFoJK77qPZw7JoBKg)

[基于约束的推荐系统](https://mp.weixin.qq.com/s/wm9A6Y52ILageW-CS8rgmw)

[情景感知推荐系统](https://mp.weixin.qq.com/s/C-KctLP9tf4k0SGVtHhZww)

[推荐系统中的数据挖掘方法](https://mp.weixin.qq.com/s/SfWiGypHV3X4V7NE_A7KtQ)

[推荐模型之用户行为序列处理](https://mp.weixin.qq.com/s/osor94Qti9CKbPh0RNO6VQ)

[NLP+基于内容的推荐](https://mp.weixin.qq.com/s/UE_6ZkS9ENQP4iKTTWzwIA)

[AAAI2021推荐系统论文清单](https://mp.weixin.qq.com/s/Z68OpRSAmMHHdxkMDD1v5g)

<p><strong>计算广告/广告系统</strong></p>

[特征交互新路线|阿里 Co-action Network论文解读](https://mp.weixin.qq.com/s/KEnkwa3ZwnIKi8ZxsPOCaQ)

[计算广告OCPC实践(四) 如何从0开始建立ocpc业务](https://mp.weixin.qq.com/s/InOm3R4Rf5KtPYDiCj2kbw)

<p><strong>搜索引擎</strong></p>

[搜索中涉及的算法问题](https://mp.weixin.qq.com/s/5EtLDC4ox3Yy5kkj2W4DIg)

<p><strong>知识图谱</strong></p>

[知识表示与融入技术前沿进展及应用](https://mp.weixin.qq.com/s/3V6vzrev4xPYKJmGqXNnAg)

[无需人工！无需训练！构建知识图谱 BERT一下就行了！](https://mp.weixin.qq.com/s/fxXpwcQx7ogay8qcLAUXsw)

[赛尔笔记 | 概念体系自动构建](https://mp.weixin.qq.com/s/ihYxmCSCNhO-i2-4q_I4fQ)

<p><strong>关系抽取</strong></p>

[刘知远老师的“灵魂发问”：关系抽取到底在乎什么？](https://mp.weixin.qq.com/s/azD5OKyTxYVVZM8eho4JXA)

<p><strong>事件抽取</strong></p>

[超全必读！事件抽取综述（上）](https://mp.weixin.qq.com/s/aQaVEk90_1Axz-67jh7S8Q)

[NLP 事件抽取综述（中）—— 模型篇](https://mp.weixin.qq.com/s/S6LvJqOlIpGWXThN212fVg)

[超全必读！NLP 事件抽取综述（下）](https://mp.weixin.qq.com/s/1naWym_yYgdERFogoxPNwQ)

<p><strong>多任务学习</strong></p>

[Multi-Task 多任务学习， 那些你不知道的事](https://mp.weixin.qq.com/s/MOSMR3Ue9i3jYklPRvmWwA)

<p><strong>竞赛之路</strong></p>

[2020 Kaggle 10大竞赛方案汇总](https://mp.weixin.qq.com/s/CLZsq01Zw_yEdtvkTyyiGg)

[一人之力，刷爆三路榜单！信息抽取竞赛夺冠经验分享](https://mp.weixin.qq.com/s/nXblUywY3b5HFwej5DNToA)

<p><strong>算法工程师之路</strong></p>

[四化大业：论算法工程师的自我修养](https://mp.weixin.qq.com/s/qaSaVsYtvWG5EDDOUi82oA)

[NLP算法工程师的日常以及核心竞争力](https://mp.weixin.qq.com/s/v7YZ_Y2a_u2HfJx0sGqFOw)

[算法在岗一年的经验总结](https://mp.weixin.qq.com/s/5q-Du1kbpb-ZYqnktsUMaQ)

<p><strong>实战经验分享</strong></p>

[如何修正NLP问题的bad case](https://mp.weixin.qq.com/s/d6G4jbprAItGp_qiHjO5uA)

<p><strong>系统架构</strong></p>

[Mesh-Tensorflow: 广义分布式训练大模型](https://mp.weixin.qq.com/s/gr8443SRnBbGT9jtRi2SoA)

<p><strong>开源工具</strong></p>

[安利一个开源的好工具Label Studio, 闭环数据标注和模型训练](https://mp.weixin.qq.com/s/kWJZA0acOPi46c2_Gd9aeA)

<p><strong>其他</strong></p>

[概率图模型系列（一）：概率图模型简介](https://mp.weixin.qq.com/s/mkM0N9eqRIT1Sx9cbBK9dg)

[【科普】 AI是什么？AI可以做什么？AI会取代人的工作吗？](https://mp.weixin.qq.com/s/SfWiGypHV3X4V7NE_A7KtQ)


<p><strong>关于AINLP</strong></p>
<p>AINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、推荐算法等相关技术的分享，主题包括文本摘要、智能问答、聊天机器人、机器翻译、自动生成、知识图谱、预训练模型、推荐系统、计算广告、招聘信息、求职经验分享等，欢迎关注！加技术交流群请添加AINLP君微信(id：AINLP2)，备注工作/研究方向+加群目的。</p>
<p align=center><img src="./images/ainlp_banner.jpg" width="800" height="323"></p>
